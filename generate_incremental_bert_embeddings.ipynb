{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from IPython.core.debugger import set_trace\n",
    "from scipy.io import loadmat\n",
    "import pickle\n",
    "import os\n",
    "import sys\n",
    "import nltk\n",
    "from scipy import stats\n",
    "from sklearn.model_selection import KFold\n",
    "from scipy.stats import spearmanr, pearsonr\n",
    "import spacy\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from spacy import displacy\n",
    "from collections import defaultdict\n",
    "import torch\n",
    "from transformers import *\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "np.random.seed(97)\n",
    "torch.manual_seed(97)\n",
    "\n",
    "save_dir = \"features\"\n",
    "if not os.path.exists(save_dir):\n",
    "    os.mkdir(save_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "hp_text = open(\"chapter9.txt\",\"r\").readlines()\n",
    "hp_text = [i.strip() for i in hp_text]\n",
    "\n",
    "sent_text = open(\"sentences.txt\", \"r\").readlines()\n",
    "all_sentences = [\"\"]\n",
    "for i in range(len(sent_text)):\n",
    "    sent_text[i] = sent_text[i].strip()\n",
    "    if len(sent_text[i]) == 0 or sent_text[i] == \"+\":\n",
    "        all_sentences.append(\"\")\n",
    "    elif sent_text[i]!=\"+\":\n",
    "        all_sentences[-1] += sent_text[i] + \" \"\n",
    "\n",
    "all_sentences_clean = [i.strip() for i in all_sentences if len(i.strip()) > 0]\n",
    "all_sentences = all_sentences_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_contexts = []\n",
    "max_len = 0\n",
    "\n",
    "for sent in all_sentences:\n",
    "    words = sent.strip().split(\" \")\n",
    "    max_len = max(max_len, len(words))\n",
    "    for i in range(len(words)):\n",
    "        if (len(all_contexts) != 0  and hp_text[len(all_contexts)] == \"+\"):\n",
    "            all_contexts.append(\"\")\n",
    "        if (len(all_contexts) != 0  and hp_text[len(all_contexts)] == \"+\"):\n",
    "            all_contexts.append(\"\")\n",
    "        all_contexts.append(\" \".join(words[:i+1]))\n",
    "            \n",
    "all_contexts.append([[\"\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5176\n"
     ]
    }
   ],
   "source": [
    "print(len(all_contexts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertModel(\n",
       "  (embeddings): BertEmbeddings(\n",
       "    (word_embeddings): Embedding(28996, 1024, padding_idx=0)\n",
       "    (position_embeddings): Embedding(512, 1024)\n",
       "    (token_type_embeddings): Embedding(2, 1024)\n",
       "    (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (encoder): BertEncoder(\n",
       "    (layer): ModuleList(\n",
       "      (0): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (1): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (2): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (3): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (4): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (5): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (6): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (7): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (8): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (9): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (10): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (11): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (12): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (13): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (14): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (15): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (16): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (17): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (18): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (19): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (20): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (21): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (22): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (23): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (pooler): BertPooler(\n",
       "    (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "    (activation): Tanh()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained('bert-large-cased')\n",
    "model = BertModel.from_pretrained('bert-large-cased', output_hidden_states=True)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Harry\n",
      "Harry\n",
      "had\n",
      "Harry had\n",
      "never\n",
      "Harry had never\n",
      "believed\n",
      "Harry had never believed\n",
      "he\n",
      "Harry had never believed he\n",
      "would\n",
      "Harry had never believed he would\n",
      "meet\n",
      "Harry had never believed he would meet\n",
      "a\n",
      "Harry had never believed he would meet a\n",
      "boy\n",
      "Harry had never believed he would meet a boy\n",
      "he\n",
      "Harry had never believed he would meet a boy he\n",
      "hated\n",
      "Harry had never believed he would meet a boy he hated\n",
      "more\n",
      "Harry had never believed he would meet a boy he hated more\n",
      "than\n",
      "Harry had never believed he would meet a boy he hated more than\n",
      "Dudley,\n",
      "Harry had never believed he would meet a boy he hated more than Dudley,\n",
      "but\n",
      "Harry had never believed he would meet a boy he hated more than Dudley, but\n",
      "that\n",
      "Harry had never believed he would meet a boy he hated more than Dudley, but that\n",
      "was\n",
      "Harry had never believed he would meet a boy he hated more than Dudley, but that was\n",
      "before\n",
      "Harry had never believed he would meet a boy he hated more than Dudley, but that was before\n",
      "he\n",
      "Harry had never believed he would meet a boy he hated more than Dudley, but that was before he\n",
      "met\n",
      "Harry had never believed he would meet a boy he hated more than Dudley, but that was before he met\n",
      "Draco\n",
      "Harry had never believed he would meet a boy he hated more than Dudley, but that was before he met Draco\n",
      "Malfoy.\n",
      "Harry had never believed he would meet a boy he hated more than Dudley, but that was before he met Draco Malfoy.\n",
      "Still,\n",
      "Still,\n",
      "first-year\n",
      "Still, first-year\n",
      "Gryffindors\n",
      "Still, first-year Gryffindors\n",
      "only\n",
      "Still, first-year Gryffindors only\n",
      "had\n",
      "Still, first-year Gryffindors only had\n",
      "Potions\n",
      "Still, first-year Gryffindors only had Potions\n",
      "with\n",
      "Still, first-year Gryffindors only had Potions with\n",
      "the\n",
      "Still, first-year Gryffindors only had Potions with the\n",
      "Slytherins,\n",
      "Still, first-year Gryffindors only had Potions with the Slytherins,\n",
      "so\n",
      "Still, first-year Gryffindors only had Potions with the Slytherins, so\n",
      "they\n",
      "Still, first-year Gryffindors only had Potions with the Slytherins, so they\n",
      "didn't\n",
      "Still, first-year Gryffindors only had Potions with the Slytherins, so they didn't\n",
      "have\n",
      "Still, first-year Gryffindors only had Potions with the Slytherins, so they didn't have\n",
      "to\n",
      "Still, first-year Gryffindors only had Potions with the Slytherins, so they didn't have to\n",
      "put\n",
      "Still, first-year Gryffindors only had Potions with the Slytherins, so they didn't have to put\n",
      "up\n",
      "Still, first-year Gryffindors only had Potions with the Slytherins, so they didn't have to put up\n",
      "with\n",
      "Still, first-year Gryffindors only had Potions with the Slytherins, so they didn't have to put up with\n",
      "Malfoy\n",
      "Still, first-year Gryffindors only had Potions with the Slytherins, so they didn't have to put up with Malfoy\n",
      "much.\n",
      "Still, first-year Gryffindors only had Potions with the Slytherins, so they didn't have to put up with Malfoy much.\n",
      "Or\n",
      "Or\n",
      "at\n",
      "Or at\n",
      "least,\n",
      "Or at least,\n",
      "they\n",
      "Or at least, they\n",
      "didn't\n",
      "Or at least, they didn't\n",
      "until\n",
      "Or at least, they didn't until\n",
      "they\n",
      "Or at least, they didn't until they\n",
      "spotted\n",
      "Or at least, they didn't until they spotted\n",
      "a\n",
      "Or at least, they didn't until they spotted a\n",
      "notice\n",
      "Or at least, they didn't until they spotted a notice\n",
      "pinned\n",
      "Or at least, they didn't until they spotted a notice pinned\n",
      "up\n",
      "Or at least, they didn't until they spotted a notice pinned up\n",
      "in\n",
      "Or at least, they didn't until they spotted a notice pinned up in\n",
      "the\n",
      "Or at least, they didn't until they spotted a notice pinned up in the\n",
      "Gryffindor\n",
      "Or at least, they didn't until they spotted a notice pinned up in the Gryffindor\n",
      "common\n",
      "Or at least, they didn't until they spotted a notice pinned up in the Gryffindor common\n",
      "room\n",
      "Or at least, they didn't until they spotted a notice pinned up in the Gryffindor common room\n",
      "that\n",
      "Or at least, they didn't until they spotted a notice pinned up in the Gryffindor common room that\n",
      "made\n",
      "Or at least, they didn't until they spotted a notice pinned up in the Gryffindor common room that made\n",
      "them\n",
      "Or at least, they didn't until they spotted a notice pinned up in the Gryffindor common room that made them\n",
      "all\n",
      "Or at least, they didn't until they spotted a notice pinned up in the Gryffindor common room that made them all\n",
      "groan.\n",
      "Or at least, they didn't until they spotted a notice pinned up in the Gryffindor common room that made them all groan.\n",
      "Flying\n",
      "Flying\n",
      "lessons\n",
      "Flying lessons\n",
      "would\n",
      "Flying lessons would\n",
      "be\n",
      "Flying lessons would be\n",
      "starting\n",
      "Flying lessons would be starting\n",
      "on\n",
      "Flying lessons would be starting on\n",
      "Thursday\n",
      "Flying lessons would be starting on Thursday\n",
      "--\n",
      "Flying lessons would be starting on Thursday --\n",
      "and\n",
      "Flying lessons would be starting on Thursday -- and\n",
      "Gryffindor\n",
      "Flying lessons would be starting on Thursday -- and Gryffindor\n",
      "and\n",
      "Flying lessons would be starting on Thursday -- and Gryffindor and\n",
      "Slytherin\n",
      "Flying lessons would be starting on Thursday -- and Gryffindor and Slytherin\n",
      "would\n",
      "Flying lessons would be starting on Thursday -- and Gryffindor and Slytherin would\n",
      "be\n",
      "Flying lessons would be starting on Thursday -- and Gryffindor and Slytherin would be\n",
      "learning\n",
      "Flying lessons would be starting on Thursday -- and Gryffindor and Slytherin would be learning\n",
      "together.\n",
      "Flying lessons would be starting on Thursday -- and Gryffindor and Slytherin would be learning together.\n",
      "+\n",
      "\n",
      "\"Typical,\"\n",
      "\"Typical,\"\n",
      "said\n",
      "\"Typical,\" said\n",
      "Harry\n",
      "\"Typical,\" said Harry\n",
      "darkly.\n",
      "\"Typical,\" said Harry darkly.\n",
      "\"Just\n",
      "\"Just\n",
      "what\n",
      "\"Just what\n",
      "I\n",
      "\"Just what I\n",
      "always\n",
      "\"Just what I always\n",
      "wanted.\n",
      "\"Just what I always wanted.\n",
      "To\n",
      "To\n",
      "make\n",
      "To make\n",
      "a\n",
      "To make a\n",
      "fool\n",
      "To make a fool\n",
      "of\n",
      "To make a fool of\n",
      "myself\n",
      "To make a fool of myself\n",
      "on\n",
      "To make a fool of myself on\n",
      "a\n",
      "To make a fool of myself on a\n",
      "broomstick\n",
      "To make a fool of myself on a broomstick\n",
      "in\n",
      "To make a fool of myself on a broomstick in\n",
      "front\n",
      "To make a fool of myself on a broomstick in front\n",
      "of\n",
      "To make a fool of myself on a broomstick in front of\n",
      "Malfoy.\"\n",
      "To make a fool of myself on a broomstick in front of Malfoy.\"\n",
      "+\n",
      "\n",
      "He\n",
      "He\n",
      "had\n",
      "He had\n",
      "been\n",
      "He had been\n",
      "looking\n",
      "He had been looking\n",
      "forward\n",
      "He had been looking forward\n",
      "to\n",
      "He had been looking forward to\n",
      "learning\n",
      "He had been looking forward to learning\n",
      "to\n",
      "He had been looking forward to learning to\n",
      "fly\n",
      "He had been looking forward to learning to fly\n",
      "more\n",
      "He had been looking forward to learning to fly more\n",
      "than\n",
      "He had been looking forward to learning to fly more than\n",
      "anything\n",
      "He had been looking forward to learning to fly more than anything\n",
      "else.\n",
      "He had been looking forward to learning to fly more than anything else.\n",
      "\"You\n",
      "\"You\n",
      "don't\n",
      "\"You don't\n",
      "know\n",
      "\"You don't know\n",
      "that\n",
      "\"You don't know that\n",
      "you'll\n",
      "\"You don't know that you'll\n",
      "make\n",
      "\"You don't know that you'll make\n",
      "a\n",
      "\"You don't know that you'll make a\n",
      "fool\n",
      "\"You don't know that you'll make a fool\n",
      "of\n",
      "\"You don't know that you'll make a fool of\n",
      "yourself,\"\n",
      "\"You don't know that you'll make a fool of yourself,\"\n",
      "said\n",
      "\"You don't know that you'll make a fool of yourself,\" said\n",
      "Ron\n",
      "\"You don't know that you'll make a fool of yourself,\" said Ron\n",
      "reasonably.\n",
      "\"You don't know that you'll make a fool of yourself,\" said Ron reasonably.\n",
      "\"Anyway,\n",
      "\"Anyway,\n",
      "I\n",
      "\"Anyway, I\n",
      "know\n",
      "\"Anyway, I know\n",
      "Malfoy's\n",
      "\"Anyway, I know Malfoy's\n",
      "always\n",
      "\"Anyway, I know Malfoy's always\n",
      "going\n",
      "\"Anyway, I know Malfoy's always going\n",
      "on\n",
      "\"Anyway, I know Malfoy's always going on\n",
      "about\n",
      "\"Anyway, I know Malfoy's always going on about\n",
      "how\n",
      "\"Anyway, I know Malfoy's always going on about how\n",
      "good\n",
      "\"Anyway, I know Malfoy's always going on about how good\n",
      "he\n",
      "\"Anyway, I know Malfoy's always going on about how good he\n",
      "is\n",
      "\"Anyway, I know Malfoy's always going on about how good he is\n",
      "at\n",
      "\"Anyway, I know Malfoy's always going on about how good he is at\n",
      "Quidditch,\n",
      "\"Anyway, I know Malfoy's always going on about how good he is at Quidditch,\n",
      "but\n",
      "\"Anyway, I know Malfoy's always going on about how good he is at Quidditch, but\n",
      "I\n",
      "\"Anyway, I know Malfoy's always going on about how good he is at Quidditch, but I\n",
      "bet\n",
      "\"Anyway, I know Malfoy's always going on about how good he is at Quidditch, but I bet\n",
      "that's\n",
      "\"Anyway, I know Malfoy's always going on about how good he is at Quidditch, but I bet that's\n",
      "all\n",
      "\"Anyway, I know Malfoy's always going on about how good he is at Quidditch, but I bet that's all\n",
      "talk.\"\n",
      "\"Anyway, I know Malfoy's always going on about how good he is at Quidditch, but I bet that's all talk.\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+\n",
      "\n",
      "Malfoy\n",
      "Malfoy\n",
      "certainly\n",
      "Malfoy certainly\n",
      "did\n",
      "Malfoy certainly did\n",
      "talk\n",
      "Malfoy certainly did talk\n",
      "about\n",
      "Malfoy certainly did talk about\n",
      "flying\n",
      "Malfoy certainly did talk about flying\n",
      "a\n",
      "Malfoy certainly did talk about flying a\n",
      "lot.\n",
      "Malfoy certainly did talk about flying a lot.\n",
      "He\n",
      "He\n",
      "complained\n",
      "He complained\n",
      "loudly\n",
      "He complained loudly\n",
      "about\n",
      "He complained loudly about\n",
      "first\n",
      "He complained loudly about first\n",
      "years\n",
      "He complained loudly about first years\n",
      "never\n",
      "He complained loudly about first years never\n",
      "getting\n",
      "He complained loudly about first years never getting\n",
      "on\n",
      "He complained loudly about first years never getting on\n",
      "the\n",
      "He complained loudly about first years never getting on the\n",
      "House\n",
      "He complained loudly about first years never getting on the House\n",
      "Quidditch\n",
      "He complained loudly about first years never getting on the House Quidditch\n",
      "teams\n",
      "He complained loudly about first years never getting on the House Quidditch teams\n",
      "and\n",
      "He complained loudly about first years never getting on the House Quidditch teams and\n",
      "told\n",
      "He complained loudly about first years never getting on the House Quidditch teams and told\n",
      "long,\n",
      "He complained loudly about first years never getting on the House Quidditch teams and told long,\n",
      "boastful\n",
      "He complained loudly about first years never getting on the House Quidditch teams and told long, boastful\n",
      "stories\n",
      "He complained loudly about first years never getting on the House Quidditch teams and told long, boastful stories\n",
      "that\n",
      "He complained loudly about first years never getting on the House Quidditch teams and told long, boastful stories that\n",
      "always\n",
      "He complained loudly about first years never getting on the House Quidditch teams and told long, boastful stories that always\n",
      "seemed\n",
      "He complained loudly about first years never getting on the House Quidditch teams and told long, boastful stories that always seemed\n",
      "to\n",
      "He complained loudly about first years never getting on the House Quidditch teams and told long, boastful stories that always seemed to\n",
      "end\n",
      "He complained loudly about first years never getting on the House Quidditch teams and told long, boastful stories that always seemed to end\n",
      "with\n",
      "He complained loudly about first years never getting on the House Quidditch teams and told long, boastful stories that always seemed to end with\n",
      "him\n",
      "He complained loudly about first years never getting on the House Quidditch teams and told long, boastful stories that always seemed to end with him\n",
      "narrowly\n",
      "He complained loudly about first years never getting on the House Quidditch teams and told long, boastful stories that always seemed to end with him narrowly\n",
      "escaping\n",
      "He complained loudly about first years never getting on the House Quidditch teams and told long, boastful stories that always seemed to end with him narrowly escaping\n",
      "Muggles\n",
      "He complained loudly about first years never getting on the House Quidditch teams and told long, boastful stories that always seemed to end with him narrowly escaping Muggles\n",
      "in\n",
      "He complained loudly about first years never getting on the House Quidditch teams and told long, boastful stories that always seemed to end with him narrowly escaping Muggles in\n",
      "helicopters.\n",
      "He complained loudly about first years never getting on the House Quidditch teams and told long, boastful stories that always seemed to end with him narrowly escaping Muggles in helicopters.\n",
      "He\n",
      "He\n",
      "wasn't\n",
      "He wasn't\n",
      "the\n",
      "He wasn't the\n",
      "only\n",
      "He wasn't the only\n",
      "one,\n",
      "He wasn't the only one,\n",
      "though:\n",
      "He wasn't the only one, though:\n",
      "the\n",
      "He wasn't the only one, though: the\n",
      "way\n",
      "He wasn't the only one, though: the way\n",
      "Seamus\n",
      "He wasn't the only one, though: the way Seamus\n",
      "Finnigan\n",
      "He wasn't the only one, though: the way Seamus Finnigan\n",
      "told\n",
      "He wasn't the only one, though: the way Seamus Finnigan told\n",
      "it,\n",
      "He wasn't the only one, though: the way Seamus Finnigan told it,\n",
      "he'd\n",
      "He wasn't the only one, though: the way Seamus Finnigan told it, he'd\n",
      "spent\n",
      "He wasn't the only one, though: the way Seamus Finnigan told it, he'd spent\n",
      "most\n",
      "He wasn't the only one, though: the way Seamus Finnigan told it, he'd spent most\n",
      "of\n",
      "He wasn't the only one, though: the way Seamus Finnigan told it, he'd spent most of\n",
      "his\n",
      "He wasn't the only one, though: the way Seamus Finnigan told it, he'd spent most of his\n",
      "childhood\n",
      "He wasn't the only one, though: the way Seamus Finnigan told it, he'd spent most of his childhood\n",
      "zooming\n",
      "He wasn't the only one, though: the way Seamus Finnigan told it, he'd spent most of his childhood zooming\n",
      "around\n",
      "He wasn't the only one, though: the way Seamus Finnigan told it, he'd spent most of his childhood zooming around\n",
      "the\n",
      "He wasn't the only one, though: the way Seamus Finnigan told it, he'd spent most of his childhood zooming around the\n",
      "countryside\n",
      "He wasn't the only one, though: the way Seamus Finnigan told it, he'd spent most of his childhood zooming around the countryside\n",
      "on\n",
      "He wasn't the only one, though: the way Seamus Finnigan told it, he'd spent most of his childhood zooming around the countryside on\n",
      "his\n",
      "He wasn't the only one, though: the way Seamus Finnigan told it, he'd spent most of his childhood zooming around the countryside on his\n",
      "broomstick.\n",
      "He wasn't the only one, though: the way Seamus Finnigan told it, he'd spent most of his childhood zooming around the countryside on his broomstick.\n",
      "Even\n",
      "Even\n",
      "Ron\n",
      "Even Ron\n",
      "would\n",
      "Even Ron would\n",
      "tell\n",
      "Even Ron would tell\n",
      "anyone\n",
      "Even Ron would tell anyone\n",
      "who'd\n",
      "Even Ron would tell anyone who'd\n",
      "listen\n",
      "Even Ron would tell anyone who'd listen\n",
      "about\n",
      "Even Ron would tell anyone who'd listen about\n",
      "the\n",
      "Even Ron would tell anyone who'd listen about the\n",
      "time\n",
      "Even Ron would tell anyone who'd listen about the time\n",
      "he'd\n",
      "Even Ron would tell anyone who'd listen about the time he'd\n",
      "almost\n",
      "Even Ron would tell anyone who'd listen about the time he'd almost\n",
      "hit\n",
      "Even Ron would tell anyone who'd listen about the time he'd almost hit\n",
      "a\n",
      "Even Ron would tell anyone who'd listen about the time he'd almost hit a\n",
      "hang\n",
      "Even Ron would tell anyone who'd listen about the time he'd almost hit a hang\n",
      "glider\n",
      "Even Ron would tell anyone who'd listen about the time he'd almost hit a hang glider\n",
      "on\n",
      "Even Ron would tell anyone who'd listen about the time he'd almost hit a hang glider on\n",
      "Charlie's\n",
      "Even Ron would tell anyone who'd listen about the time he'd almost hit a hang glider on Charlie's\n",
      "old\n",
      "Even Ron would tell anyone who'd listen about the time he'd almost hit a hang glider on Charlie's old\n",
      "broom.\n",
      "Even Ron would tell anyone who'd listen about the time he'd almost hit a hang glider on Charlie's old broom.\n",
      "Everyone\n",
      "Everyone\n",
      "from\n",
      "Everyone from\n",
      "wizarding\n",
      "Everyone from wizarding\n",
      "families\n",
      "Everyone from wizarding families\n",
      "talked\n",
      "Everyone from wizarding families talked\n",
      "about\n",
      "Everyone from wizarding families talked about\n",
      "Quidditch\n",
      "Everyone from wizarding families talked about Quidditch\n",
      "constantly.\n",
      "Everyone from wizarding families talked about Quidditch constantly.\n",
      "Ron\n",
      "Ron\n",
      "had\n",
      "Ron had\n",
      "already\n",
      "Ron had already\n",
      "had\n",
      "Ron had already had\n",
      "a\n",
      "Ron had already had a\n",
      "big\n",
      "Ron had already had a big\n",
      "argument\n",
      "Ron had already had a big argument\n",
      "with\n",
      "Ron had already had a big argument with\n",
      "Dean\n",
      "Ron had already had a big argument with Dean\n",
      "Thomas,\n",
      "Ron had already had a big argument with Dean Thomas,\n",
      "who\n",
      "Ron had already had a big argument with Dean Thomas, who\n",
      "shared\n",
      "Ron had already had a big argument with Dean Thomas, who shared\n",
      "their\n",
      "Ron had already had a big argument with Dean Thomas, who shared their\n",
      "dormitory,\n",
      "Ron had already had a big argument with Dean Thomas, who shared their dormitory,\n",
      "about\n",
      "Ron had already had a big argument with Dean Thomas, who shared their dormitory, about\n",
      "soccer.\n",
      "Ron had already had a big argument with Dean Thomas, who shared their dormitory, about soccer.\n",
      "Ron\n",
      "Ron\n",
      "couldn't\n",
      "Ron couldn't\n",
      "see\n",
      "Ron couldn't see\n",
      "what\n",
      "Ron couldn't see what\n",
      "was\n",
      "Ron couldn't see what was\n",
      "exciting\n",
      "Ron couldn't see what was exciting\n",
      "about\n",
      "Ron couldn't see what was exciting about\n",
      "a\n",
      "Ron couldn't see what was exciting about a\n",
      "game\n",
      "Ron couldn't see what was exciting about a game\n",
      "with\n",
      "Ron couldn't see what was exciting about a game with\n",
      "only\n",
      "Ron couldn't see what was exciting about a game with only\n",
      "one\n",
      "Ron couldn't see what was exciting about a game with only one\n",
      "ball\n",
      "Ron couldn't see what was exciting about a game with only one ball\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "where\n",
      "Ron couldn't see what was exciting about a game with only one ball where\n",
      "no\n",
      "Ron couldn't see what was exciting about a game with only one ball where no\n",
      "one\n",
      "Ron couldn't see what was exciting about a game with only one ball where no one\n",
      "was\n",
      "Ron couldn't see what was exciting about a game with only one ball where no one was\n",
      "allowed\n",
      "Ron couldn't see what was exciting about a game with only one ball where no one was allowed\n",
      "to\n",
      "Ron couldn't see what was exciting about a game with only one ball where no one was allowed to\n",
      "fly.\n",
      "Ron couldn't see what was exciting about a game with only one ball where no one was allowed to fly.\n",
      "Harry\n",
      "Harry\n",
      "had\n",
      "Harry had\n",
      "caught\n",
      "Harry had caught\n",
      "Ron\n",
      "Harry had caught Ron\n",
      "prodding\n",
      "Harry had caught Ron prodding\n",
      "Dean's\n",
      "Harry had caught Ron prodding Dean's\n",
      "poster\n",
      "Harry had caught Ron prodding Dean's poster\n",
      "of\n",
      "Harry had caught Ron prodding Dean's poster of\n",
      "West\n",
      "Harry had caught Ron prodding Dean's poster of West\n",
      "Ham\n",
      "Harry had caught Ron prodding Dean's poster of West Ham\n",
      "soccer\n",
      "Harry had caught Ron prodding Dean's poster of West Ham soccer\n",
      "team,\n",
      "Harry had caught Ron prodding Dean's poster of West Ham soccer team,\n",
      "trying\n",
      "Harry had caught Ron prodding Dean's poster of West Ham soccer team, trying\n",
      "to\n",
      "Harry had caught Ron prodding Dean's poster of West Ham soccer team, trying to\n",
      "make\n",
      "Harry had caught Ron prodding Dean's poster of West Ham soccer team, trying to make\n",
      "the\n",
      "Harry had caught Ron prodding Dean's poster of West Ham soccer team, trying to make the\n",
      "players\n",
      "Harry had caught Ron prodding Dean's poster of West Ham soccer team, trying to make the players\n",
      "move.\n",
      "Harry had caught Ron prodding Dean's poster of West Ham soccer team, trying to make the players move.\n",
      "+\n",
      "\n",
      "Neville\n",
      "Neville\n",
      "had\n",
      "Neville had\n",
      "never\n",
      "Neville had never\n",
      "been\n",
      "Neville had never been\n",
      "on\n",
      "Neville had never been on\n",
      "a\n",
      "Neville had never been on a\n",
      "broomstick\n",
      "Neville had never been on a broomstick\n",
      "in\n",
      "Neville had never been on a broomstick in\n",
      "his\n",
      "Neville had never been on a broomstick in his\n",
      "life,\n",
      "Neville had never been on a broomstick in his life,\n",
      "because\n",
      "Neville had never been on a broomstick in his life, because\n",
      "his\n",
      "Neville had never been on a broomstick in his life, because his\n",
      "grandmother\n",
      "Neville had never been on a broomstick in his life, because his grandmother\n",
      "had\n",
      "Neville had never been on a broomstick in his life, because his grandmother had\n",
      "never\n",
      "Neville had never been on a broomstick in his life, because his grandmother had never\n",
      "let\n",
      "Neville had never been on a broomstick in his life, because his grandmother had never let\n",
      "him\n",
      "Neville had never been on a broomstick in his life, because his grandmother had never let him\n",
      "near\n",
      "Neville had never been on a broomstick in his life, because his grandmother had never let him near\n",
      "one.\n",
      "Neville had never been on a broomstick in his life, because his grandmother had never let him near one.\n",
      "Privately,\n",
      "Privately,\n",
      "Harry\n",
      "Privately, Harry\n",
      "felt\n",
      "Privately, Harry felt\n",
      "she'd\n",
      "Privately, Harry felt she'd\n",
      "had\n",
      "Privately, Harry felt she'd had\n",
      "good\n",
      "Privately, Harry felt she'd had good\n",
      "reason,\n",
      "Privately, Harry felt she'd had good reason,\n",
      "because\n",
      "Privately, Harry felt she'd had good reason, because\n",
      "Neville\n",
      "Privately, Harry felt she'd had good reason, because Neville\n",
      "managed\n",
      "Privately, Harry felt she'd had good reason, because Neville managed\n",
      "to\n",
      "Privately, Harry felt she'd had good reason, because Neville managed to\n",
      "have\n",
      "Privately, Harry felt she'd had good reason, because Neville managed to have\n",
      "an\n",
      "Privately, Harry felt she'd had good reason, because Neville managed to have an\n",
      "extraordinary\n",
      "Privately, Harry felt she'd had good reason, because Neville managed to have an extraordinary\n",
      "number\n",
      "Privately, Harry felt she'd had good reason, because Neville managed to have an extraordinary number\n",
      "of\n",
      "Privately, Harry felt she'd had good reason, because Neville managed to have an extraordinary number of\n",
      "accidents\n",
      "Privately, Harry felt she'd had good reason, because Neville managed to have an extraordinary number of accidents\n",
      "even\n",
      "Privately, Harry felt she'd had good reason, because Neville managed to have an extraordinary number of accidents even\n",
      "with\n",
      "Privately, Harry felt she'd had good reason, because Neville managed to have an extraordinary number of accidents even with\n",
      "both\n",
      "Privately, Harry felt she'd had good reason, because Neville managed to have an extraordinary number of accidents even with both\n",
      "feet\n",
      "Privately, Harry felt she'd had good reason, because Neville managed to have an extraordinary number of accidents even with both feet\n",
      "on\n",
      "Privately, Harry felt she'd had good reason, because Neville managed to have an extraordinary number of accidents even with both feet on\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-0553e3d9edd5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0minput_ids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_contexts\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madd_special_tokens\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Add special tokens takes care of adding [CLS], [SEP], <s>... tokens in the right way for each model.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m         \u001b[0mall_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m         \u001b[0mall_hidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mall_outputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0mselected_hidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mall_hidden_states\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mselected_layer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    720\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    721\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 722\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    723\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    724\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/transformers/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    839\u001b[0m             \u001b[0moutput_attentions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_attentions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    840\u001b[0m             \u001b[0moutput_hidden_states\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_hidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 841\u001b[0;31m             \u001b[0mreturn_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreturn_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    842\u001b[0m         )\n\u001b[1;32m    843\u001b[0m         \u001b[0msequence_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mencoder_outputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    720\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    721\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 722\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    723\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    724\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/transformers/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    480\u001b[0m                     \u001b[0mencoder_hidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    481\u001b[0m                     \u001b[0mencoder_attention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 482\u001b[0;31m                     \u001b[0moutput_attentions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    483\u001b[0m                 )\n\u001b[1;32m    484\u001b[0m             \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer_outputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    720\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    721\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 722\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    723\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    724\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/transformers/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, output_attentions)\u001b[0m\n\u001b[1;32m    421\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    422\u001b[0m         layer_output = apply_chunking_to_forward(\n\u001b[0;32m--> 423\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeed_forward_chunk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchunk_size_feed_forward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseq_len_dim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_output\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    424\u001b[0m         )\n\u001b[1;32m    425\u001b[0m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlayer_output\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/transformers/modeling_utils.py\u001b[0m in \u001b[0;36mapply_chunking_to_forward\u001b[0;34m(forward_fn, chunk_size, chunk_dim, *input_tensors)\u001b[0m\n\u001b[1;32m   1670\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_chunks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mchunk_dim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1671\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1672\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mforward_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput_tensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/transformers/modeling_bert.py\u001b[0m in \u001b[0;36mfeed_forward_chunk\u001b[0;34m(self, attention_output)\u001b[0m\n\u001b[1;32m    427\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    428\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfeed_forward_chunk\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 429\u001b[0;31m         \u001b[0mintermediate_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mintermediate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mattention_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    430\u001b[0m         \u001b[0mlayer_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mintermediate_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    431\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mlayer_output\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    720\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    721\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 722\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    723\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    724\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/transformers/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states)\u001b[0m\n\u001b[1;32m    354\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    355\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 356\u001b[0;31m         \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    357\u001b[0m         \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mintermediate_act_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    358\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mhidden_states\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    720\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    721\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 722\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    723\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    724\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     89\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 91\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mlinear\u001b[0;34m(input, weight, bias)\u001b[0m\n\u001b[1;32m   1676\u001b[0m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1677\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mbias\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1678\u001b[0;31m             \u001b[0moutput\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1679\u001b[0m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1680\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mret\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "all_embeddings = []\n",
    "selected_layer = 11\n",
    "\n",
    "for i in range(len(all_contexts)):\n",
    "    print(hp_text[i])\n",
    "    print(all_contexts[i])\n",
    "    if hp_text[i] == \"+\":\n",
    "        all_embeddings.append(np.zeros(1024))\n",
    "    else:\n",
    "        input_ids = torch.tensor([tokenizer.encode(all_contexts[i], add_special_tokens=True)])  # Add special tokens takes care of adding [CLS], [SEP], <s>... tokens in the right way for each model.\n",
    "        all_outputs = model(input_ids)\n",
    "        all_hidden_states = all_outputs[2]\n",
    "        selected_hidden_states = all_hidden_states[selected_layer]\n",
    "        selected_hidden_states = selected_hidden_states.reshape((selected_hidden_states.shape[1], selected_hidden_states.shape[2]))\n",
    "        mean_hidden_states = selected_hidden_states.mean(axis = 0).detach().numpy()\n",
    "        all_embeddings.append(mean_hidden_states)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array(all_embeddings).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_embeddings = np.load(os.path.join(save_dir,\"incremental_bert_embeddings_layer12.npy\"))\n",
    "pca = PCA(n_components=15)\n",
    "np.random.seed(97)\n",
    "\n",
    "reduced = pca.fit_transform(np.array(all_embeddings))\n",
    "np.save(os.path.join(save_dir,\"incremental_bert_embeddings_layer12_PCA_dims_15\"), reduced)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5176, 15)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reduced.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "from scipy.stats import wilcoxon\n",
    "from IPython.core.debugger import set_trace\n",
    "\n",
    "np.random.seed(97)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# contrege results\n",
    "all_sets = [\"contrege_comp\", \"contrege_incomp\", \"incontrege\"]\n",
    "num_sets = 5\n",
    "sets_dir = \"features\"\n",
    "y_dir = \"ancestor_information_analysis\"\n",
    "clf = LogisticRegression(random_state=0, multi_class=\"multinomial\", max_iter=5000)\n",
    "\n",
    "y_labels = []\n",
    "all_y = []\n",
    "for level in range(2,10):\n",
    "    y = np.load(\"{}/level_{}_ancestors.npy\".format(y_dir, level))\n",
    "    y_mod = np.argmax(y, axis = 1)\n",
    "    all_y.append(y_mod)   \n",
    "    y_labels.append(\"level_{}_ancestors\".format(level))\n",
    "    \n",
    "results = []\n",
    "for se in range(len(all_sets)):\n",
    "    set_name = all_sets[se]\n",
    "    print(set_name)\n",
    "    all_x = []\n",
    "    for i in range(num_sets):\n",
    "        x = np.load(\"{}/{}_set_{}.npy\".format(sets_dir, set_name, i))\n",
    "        all_x.append(x)\n",
    "        \n",
    "    print(len(all_x))\n",
    "    print(all_x[0].shape)\n",
    "    result = {\"Feature\": set_name}\n",
    "    \n",
    "    for i in range(len(all_y)):\n",
    "        agg = 0.0\n",
    "        all_scores = [0.0]*10\n",
    "        all_chance = []\n",
    "        for x_it in all_x:\n",
    "            skf = StratifiedKFold(n_splits=10)\n",
    "            scores = cross_val_score(clf, x_it, all_y[i], cv=skf, scoring=\"accuracy\")\n",
    "            agg += scores.mean()\n",
    "            for j in range(scores.shape[0]):\n",
    "                all_scores[j] += scores[j]/len(all_x)\n",
    "            \n",
    "        for train_index, test_index in skf.split(all_x[0], all_y[i]):\n",
    "            y_train, y_test = all_y[i][train_index], all_y[i][test_index]\n",
    "            c = Counter(list(y_train))\n",
    "            majority_label, count = c.most_common()[0]\n",
    "            all_chance.append(float(count) / y_train.shape[0])\n",
    "        \n",
    "        print(all_scores)\n",
    "        agg /= len(all_x)\n",
    "        result[y_labels[i]] = agg\n",
    "        result[\"p_val_\" + y_labels[i]] = wilcoxon(all_scores, all_chance, zero_method=\"zsplit\").pvalue\n",
    "    print(result)\n",
    "    results.append(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# other features\n",
    "all_features = [\"pos_dep_tags\", \"node_count\", \"syntactic_surprisal\", \"word_frequency\", \"word_length\", \"all_complexity_metrics\", \"incremental_bert_embeddings_layer12_PCA_dims_15\"]\n",
    "features_dir = \"features\"\n",
    "y_dir = \"ancestor_information_analysis\"\n",
    "clf = LogisticRegression(random_state=0, multi_class=\"multinomial\", max_iter=5000)\n",
    "\n",
    "y_labels = []\n",
    "all_y = []\n",
    "for level in range(2,10):\n",
    "    y = np.load(\"{}/level_{}_ancestors.npy\".format(y_dir, level))\n",
    "    y_mod = np.argmax(y, axis = 1)\n",
    "    all_y.append(y_mod)   \n",
    "    y_labels.append(\"level_{}_ancestors\".format(level))\n",
    "    \n",
    "for fe in range(len(all_features)):\n",
    "    feat_name = all_features[fe]\n",
    "    print(feat_name)\n",
    "    x = np.load(\"{}/{}.npy\".format(features_dir, feat_name))\n",
    "    x = x.reshape((x.shape[0], -1))\n",
    "    \n",
    "    result = {\"Feature\": feat_name}\n",
    "    for i in range(len(all_y)):\n",
    "        all_scores = []\n",
    "        all_chance = []\n",
    "        skf = StratifiedKFold(n_splits=10)\n",
    "        scores = cross_val_score(clf, x, all_y[i], cv=skf, scoring=\"accuracy\")\n",
    "        agg = scores.mean()\n",
    "        all_scores = list(scores)\n",
    "\n",
    "        for train_index, test_index in skf.split(x, all_y[i]):\n",
    "            y_train, y_test = all_y[i][train_index], all_y[i][test_index]\n",
    "            c = Counter(list(y_train))\n",
    "            majority_label, count = c.most_common()[0]\n",
    "            all_chance.append(float(count) / y_train.shape[0])\n",
    "\n",
    "        print(all_scores)\n",
    "        result[y_labels[i]] = agg\n",
    "        result[\"p_val_\" + y_labels[i]] = wilcoxon(all_scores, all_chance, zero_method=\"zsplit\").pvalue\n",
    "        print(result[\"p_val_\" + y_labels[i]])\n",
    "    \n",
    "    print(result)\n",
    "#     results.append(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(\"syntactic_information_analysis_results.npy\", results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = np.load(\"syntactic_information_analysis_results.npy\", allow_pickle = True).tolist()\n",
    "for i in range(len(results)):\n",
    "    for k in results[i]:\n",
    "        if k.startswith(\"level\"):\n",
    "            results[i][k] *= 100\n",
    "            results[i][k] = np.round(results[i][k], 2)\n",
    "\n",
    "np.save(\"syntactic_information_analysis_results_formatted\",results)\n",
    "\n",
    "df = pd.DataFrame(results)\n",
    "df.to_csv(\"final_syntactic_information_analysis_results.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate table for label distribution\n",
    "dist = []\n",
    "label_names = {0: \"noun_phrase\", 1: \"verb_phrase\", 2: \"adverb_phrase\", 3: \"adjective_phrase\", 4: \"prepositional_phrase\", 5: \"clause\", 6: \"other\"}\n",
    "\n",
    "for i in range(len(all_y)):\n",
    "    d = {\"level\" : y_labels[i]}\n",
    "    for lab in range(7):\n",
    "        su = (all_y[i] == lab).sum()\n",
    "        d[label_names[lab]] = su\n",
    "        d[label_names[lab] + \"(%)\"] = su/all_y[i].shape[0]\n",
    "    dist.append(d)\n",
    "    \n",
    "dist_df = pd.DataFrame(dist)\n",
    "dist_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
